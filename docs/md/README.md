# Portfolio Platform - AI-Powered Interview Assistant

## ğŸ¯ Overview

**Clean, organized codebase for Jimmie's AI-powered portfolio platform**. Features Sheyla, an Indian AI avatar (based on mother) who conducts technical interviews and presents project information through natural conversation.

### Key Features
- ğŸ¤– **Sheyla AI Avatar**: Professional Indian lady voice with conversational interview capabilities
- ğŸ’¬ **Intelligent Chat**: RAG-powered responses about projects and technical experience  
- ğŸ“± **Simple Layout**: Avatar/chat on left, projects showcase on right
- â˜¸ï¸ **Production Ready**: Kubernetes deployment with proper resource management
- ğŸ”„ **Local + Cloud**: Local LLM with OpenAI GPT-4o mini fallback

---

## ğŸ“ Clean Architecture

```
Portfolio/
â”œâ”€â”€ chat/                   # ğŸ—£ï¸ SHEYLA'S PERSONALITY & RESPONSES
â”‚   â”œâ”€â”€ engines/
â”‚   â”‚   â””â”€â”€ conversation_engine.py   # Sheyla's conversation logic
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ sheyla_personality.md    # Sheyla's character and speaking style
â”‚       â””â”€â”€ interview_qa.md          # Pre-written Q&A for interviews
â”‚
â”œâ”€â”€ api/                    # ğŸ”§ BACKEND SERVICES (How frontend talks to backend)
â”‚   â”œâ”€â”€ main.py             # FastAPI entry point
â”‚   â”œâ”€â”€ settings.py         # Centralized configuration
â”‚   â”œâ”€â”€ routes/             # API endpoints
â”‚   â”‚   â”œâ”€â”€ chat.py         # Chat with Sheyla
â”‚   â”‚   â”œâ”€â”€ avatar.py       # Avatar creation/playback
â”‚   â”‚   â””â”€â”€ health.py       # System health checks
â”‚   â”œâ”€â”€ engines/            # Core processing
â”‚   â”‚   â”œâ”€â”€ rag_engine.py   # Knowledge retrieval
â”‚   â”‚   â”œâ”€â”€ llm_engine.py   # LLM integration
â”‚   â”‚   â””â”€â”€ avatar_engine.py # Avatar generation
â”‚   â””â”€â”€ services/           # External integrations
â”‚       â”œâ”€â”€ elevenlabs.py   # Text-to-speech
â”‚       â””â”€â”€ did.py          # Video avatar creation
â”‚
â”œâ”€â”€ rag/                    # ğŸ“š RAG KNOWLEDGE MANAGEMENT
â”‚   â”œâ”€â”€ notebooks/          # Jupyter notebooks for RAG experiments
â”‚   â””â”€â”€ data/               # Knowledge base documents
â”‚
â”œâ”€â”€ ui/                     # ğŸ¨ SINGLE TRUTH FRONTEND
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # React components (TypeScript)
â”‚   â”‚   â”‚   â”œâ”€â”€ AvatarPanel.tsx    # Sheyla avatar interface (LEFT SIDE)
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatPanel.tsx      # Chat with Sheyla (LEFT SIDE)
â”‚   â”‚   â”‚   â””â”€â”€ Projects.tsx       # Project showcase (RIGHT SIDE)
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â””â”€â”€ Landing.jsx        # Main page layout
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ api.ts             # API client for backend
â”‚   â””â”€â”€ vite.config.js      # Development proxy configuration
â”‚
â”œâ”€â”€ data/                   # ğŸ“„ CENTRALIZED DATA
â”‚   â”œâ”€â”€ knowledge/          # RAG knowledge base
â”‚   â”œâ”€â”€ personas/           # Avatar configurations
â”‚   â””â”€â”€ vectors/            # Vector database storage
â”‚
â””â”€â”€ k8s/                    # â˜¸ï¸ KUBERNETES DEPLOYMENT
    â”œâ”€â”€ base/               # Base manifests
    â””â”€â”€ overlays/           # Environment-specific configs
```

---

## ğŸš€ Quick Start

### 1. Development Setup
```bash
# Start the full stack locally
docker-compose up

# UI available at: http://localhost:5173
# API available at: http://localhost:8000
# API docs at: http://localhost:8000/docs
```

### 2. Kubernetes Deployment  
```bash
# Deploy to local Kubernetes
./deploy-local-k8s.sh

# Or use Make targets
make deploy-kind     # KIND cluster
make deploy-minikube # Minikube cluster
```

### 3. Test Sheyla's Responses
```bash
# Chat with Sheyla directly
curl -X POST http://localhost:8000/api/chat \\
  -H "Content-Type: application/json" \\
  -d '{"message": "Tell me about LinkOps AI-BOX"}'

# Get quick prompts
curl http://localhost:8000/api/chat/prompts
```

---

## ğŸ—£ï¸ Sheyla Avatar Configuration

### Personality
- **Name**: Sheyla (based on mother)
- **Heritage**: Indian professional
- **Voice**: Warm, clear, technically competent
- **Role**: Portfolio representative and technical interviewer

### Key Talking Points
1. **LinkOps AI-BOX**: Conversational AI for property management
2. **LinkOps Afterlife**: Open-source digital legacy platform  
3. **Technical Expertise**: DevSecOps + AI/ML combination
4. **Business Value**: Practical solutions with measurable ROI

### Interview Q&A Coverage
- Technical background and expertise
- Project deep-dives with business impact
- Architecture and scalability discussions
- Problem-solving approach and methodology

---

## ğŸ¨ UI Components (Single Truth)

### Left Side - Avatar & Chat
- **AvatarPanel.tsx**: Sheyla's intro and avatar display
- **ChatPanel.tsx**: Conversational interface with Sheyla
- **Features**: Session management, follow-up suggestions, citations

### Right Side - Projects  
- **Projects.tsx**: Showcase of LinkOps AI-BOX and Afterlife
- **Data Source**: `ui/src/data/knowledge/jimmie/projects.json`
- **Features**: Project descriptions, tech stacks, demo links

### Layout Logic
```jsx
// Landing.jsx - Main layout
<div className="grid md:grid-cols-2 gap-4">
  <div className="space-y-4">
    <AvatarPanel />        {/* Sheyla introduction */}
    <ChatPanel />          {/* Chat with Sheyla */}
  </div>
  <div className="space-y-4">
    <Projects />           {/* Project showcase */}
  </div>
</div>
```

---

## ğŸ”§ API Endpoints

### Chat API
```bash
POST /api/chat              # Chat with Sheyla
GET  /api/chat/prompts      # Get conversation starters
GET  /api/chat/health       # Chat service health
```

### Avatar API  
```bash
POST /api/avatar/create     # Create custom avatar
POST /api/avatar/talk       # Generate avatar speech
GET  /api/assets/{file}     # Serve avatar assets
```

### Health & Debug
```bash
GET  /health                # Overall system health
GET  /api/health/detailed   # Detailed service status
```

---

## ğŸ“š RAG Knowledge Management

### Knowledge Sources
```
data/knowledge/jimmie/
â”œâ”€â”€ 01-bio.md               # Personal background
â”œâ”€â”€ 02-devops.md            # DevSecOps experience  
â”œâ”€â”€ 03-aiml.md              # AI/ML expertise
â”œâ”€â”€ 04-projects.md          # Project details
â”œâ”€â”€ 05-faq.md               # Common interview Q&A
â”œâ”€â”€ 06-jade.md              # LinkOps AI-BOX specifics
â”œâ”€â”€ 07-current-context.md   # Current work focus
â””â”€â”€ 08-sheyla-avatar-context.md # Avatar personality
```

### RAG Ingestion
```bash
# Ingest knowledge base
kubectl exec deploy/portfolio-api -- python scripts/ingest.py

# Verify ingestion
curl http://localhost:8000/api/rag/health
```

---

## â˜¸ï¸ Kubernetes Configuration

### Resource Allocation (4GB VM Optimized)
```yaml
# API Service
resources:
  requests: { cpu: "200m", memory: "512Mi" }
  limits:   { cpu: "1",    memory: "2Gi" }

# UI Service  
resources:
  requests: { cpu: "100m", memory: "256Mi" }
  limits:   { cpu: "500m", memory: "512Mi" }
```

### Services Deployed
- **portfolio-api**: FastAPI backend with health checks
- **portfolio-ui**: React frontend with Nginx
- **chromadb**: Vector database for RAG
- **ollama**: Local LLM server (optional)

---

## ğŸ”„ LLM Configuration

### Primary: Local Efficiency
```bash
LLM_PROVIDER=ollama
LLM_MODEL=qwen/qwen2.5-1.5b-instruct  # 4GB RAM optimized
LLM_API_BASE=http://ollama:11434
```

### Fallback: Cloud Reliability  
```bash
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini                  # Fast, cost-effective
LLM_API_BASE=https://api.openai.com
LLM_API_KEY=sk-proj-your-key-here
```

### Configuration Switch
```bash
# Switch to OpenAI fallback
kubectl set env deploy/portfolio-api \\
  LLM_PROVIDER=openai \\
  LLM_MODEL=gpt-4o-mini \\
  LLM_API_KEY=$OPENAI_API_KEY
```

---

## ğŸ§ª Testing & Validation

### API Testing
```bash
# Health checks
curl http://localhost:8000/health

# Chat functionality  
curl -X POST http://localhost:8000/api/chat \\
  -d '{"message": "What is LinkOps AI-BOX?"}'

# Avatar functionality
curl http://localhost:8000/api/avatar/health
```

### E2E Testing
```bash
# Playwright tests
cd ui && npm run test:e2e

# Golden answer validation
python test_golden_answers.py
```

---

## ğŸ“– Documentation for Mentors

### Code Quality Features
- âœ… **Clean Architecture**: Microservice-style organization
- âœ… **Comprehensive Documentation**: Every component documented
- âœ… **Type Safety**: TypeScript frontend, Pydantic backend
- âœ… **Testing**: E2E tests + golden answer validation
- âœ… **Production Ready**: Resource limits, health checks, monitoring

### Key Review Areas
1. **API Structure**: `api/` - Clean FastAPI with proper separation
2. **Chat Logic**: `chat/` - Sheyla's personality and conversation engine
3. **UI Components**: `ui/src/components/` - Single truth components
4. **RAG Implementation**: `api/engines/rag_engine.py` - Vector search
5. **Deployment**: `k8s/` - Production-ready manifests

### Business Value Demonstration
- **LinkOps AI-BOX**: Property management automation with real ROI
- **Technical Expertise**: DevSecOps + AI/ML combination
- **Cost Optimization**: 4GB RAM deployment strategy
- **Practical AI**: Solutions that businesses can actually use

---

## ğŸ”— Project Links

- **Live Demo**: https://demo.linksmlm.com
- **GitHub**: https://github.com/jimjrxieb/shadow-link-industries
- **LinkOps Afterlife**: https://github.com/jimjrxieb/LinkOps-Afterlife

---

## ğŸ’¼ Interview Scenarios

### Technical Deep-Dive
Ask Sheyla: *"How is the LinkOps AI-BOX architected?"*
- RAG architecture explanation
- Local LLM deployment strategy
- Kubernetes resource optimization

### Business Impact  
Ask Sheyla: *"What's the ROI of these solutions?"*
- Property management time savings (10-15 hours/week)
- Cost analysis and payback period
- Target market and customer validation

### Problem-Solving
Ask Sheyla: *"What's the biggest technical challenge solved?"*
- 4GB RAM constraint optimization
- Local-first with cloud fallbacks
- Production deployment strategies

---

**Ready for technical interviews with a clean, documented, production-ready codebase that demonstrates real business value.**